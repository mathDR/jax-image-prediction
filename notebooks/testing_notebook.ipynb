{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fa05f15",
   "metadata": {},
   "source": [
    "# Testing Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac44a47",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556e4078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ~/dev/marthaler/header.py\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Any, Tuple\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import warnings\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "plt.rc('figure', figsize=(16, 10))\n",
    "plt.rc('font', size=14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4da2bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import equinox as eqx\n",
    "import jax\n",
    "from jax import vmap\n",
    "import jax.lax as lax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrandom\n",
    "import numpy as np\n",
    "import optax  # https://github.com/deepmind/optax\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484e4992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxtyping import Array, Float, Int, PyTree  # https://github.com/google/jaxtyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317e45ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4c4123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.lib import xla_bridge\n",
    "print(xla_bridge.get_backend().platform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968b6a8c",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa03de14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_image(\n",
    "    img: np.ndarray[np.uint8],\n",
    "    horizontal_shift: int,\n",
    "    vertical_shift: int,\n",
    ")->np.ndarray[np.uint8]:\n",
    "    \"\"\"\n",
    "      Function to shift an image by fixed numbers of pixels and fill in with 0.\n",
    "      \n",
    "      The image origin in numpy are at the top-left corner so to get a positive\n",
    "      vertical shift, we need to negate the vertical shift value passed in.\n",
    "      \n",
    "      :param img: The input image\n",
    "      :type img: np.ndarray[np.uint8]\n",
    "      :param horizontal_shift: the number of pixels to shift horizontally\n",
    "      :type horizontal_shift: int\n",
    "      :param vertical_shift: the number of pixels to shift vertically\n",
    "      :type vertical_shift: int\n",
    "      :return: The shifted image\n",
    "      :rtype: np.ndarray[np.uint8]\n",
    "    \"\"\"\n",
    "    # Negate the vertical shift to compensate for the origin at the top-left of image\n",
    "    vertical_shift = -vertical_shift\n",
    "    shift_img = np.roll(img, vertical_shift, axis=0)\n",
    "    shift_img = np.roll(shift_img, horizontal_shift, axis=1)\n",
    "    if vertical_shift>0:\n",
    "        shift_img[:vertical_shift, :] = 0\n",
    "    elif vertical_shift<0:\n",
    "        shift_img[vertical_shift:, :] = 0\n",
    "    if horizontal_shift>0:\n",
    "        shift_img[:, :horizontal_shift] = 0\n",
    "    elif horizontal_shift<0:\n",
    "        shift_img[:, horizontal_shift:] = 0\n",
    "    return shift_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed149c0",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e9e231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "in_shape=[10, 1, 64, 64]\n",
    "spatio_kernel_enc = 3\n",
    "spatio_kernel_dec = 3\n",
    "model_type = 'gSTA'\n",
    "hid_S = 64\n",
    "hid_T = 512\n",
    "N_T = 8\n",
    "N_S = 2\n",
    "# training\n",
    "lr = 1e-3\n",
    "SEED = 42\n",
    "batch_size = 16\n",
    "val_batch_size=16\n",
    "num_workers=8\n",
    "drop_path = 0\n",
    "sched = 'onecycle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa6550a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "epochs=1000\n",
    "log_step=1\n",
    "lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc349b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = np.load('/Users/daniel.marthaler/dev/SimVP/data/moving_mnist/mnist_test_seq.npy')\n",
    "from dataloader_moving_mnist import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcceb588",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, vali_loader, test_loader, data_mean, data_std = load_data(\n",
    "    batch_size,\n",
    "    val_batch_size,\n",
    "    '/Users/daniel.marthaler/dev/SimVP/data',\n",
    "    num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e83030",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch, y_batch = next(iter(train_loader))\n",
    "x_batch = x_batch.numpy()\n",
    "y_batch = y_batch.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa84b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "from functools import partial\n",
    "\n",
    "#x = jnp.arange(5 * 8 * 8 * 3).reshape(5, 8, 8, 3)\n",
    "#pixel_shuffle(x) = print(x.shape) # (5, 4, 4, 12)\n",
    "# pixel_unshuffle(pixel_shuffle(x)) = print(x.shape) # (5, 8, 8, 3)\n",
    "\n",
    "class PixelShuffle(eqx.Module):\n",
    "    scale_factor: int\n",
    "    layer: partial\n",
    "\n",
    "    def __init__(self, scale_factor: int)->None:\n",
    "        self.scale_factor = scale_factor\n",
    "        self.layer = partial(\n",
    "            rearrange,\n",
    "            pattern='... (c b1 b2) h w -> ... c (h b1) (w b2)',\n",
    "            b1=self.scale_factor,\n",
    "            b2=self.scale_factor\n",
    "        )\n",
    "\n",
    "    def __call__(self, x: Array, key: jax.random.PRNGKey=None) -> Array:\n",
    "        return self.layer(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd285fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv2d(eqx.Module):\n",
    "    act_norm: bool\n",
    "    conv: list\n",
    "    norm: eqx.nn.GroupNorm\n",
    "    act: jax.nn.silu\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        key: jax.random.PRNGKey,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: Union[int, Sequence[int]]=3,\n",
    "        stride: Union[int, Sequence[int]]=1,\n",
    "        padding: Union[str, int, Sequence[int]]=0,\n",
    "        dilation: Union[str, int, Sequence[int]]=1,\n",
    "        upsampling: bool=False,\n",
    "        act_norm: bool=False,\n",
    "        act_inplace: bool=True,\n",
    "    )->None:\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.act_norm = act_norm\n",
    "        if upsampling is True:\n",
    "            self.conv = eqx.nn.Sequential([*[\n",
    "                eqx.nn.Conv2d(in_channels, out_channels*4, kernel_size=kernel_size,\n",
    "                          stride=stride, padding=padding, dilation=dilation, key=key),\n",
    "                PixelShuffle(2)\n",
    "            ]])\n",
    "        else:\n",
    "            self.conv = eqx.nn.Conv2d(\n",
    "                in_channels, out_channels, kernel_size=kernel_size,\n",
    "                stride=stride, padding=padding, dilation=dilation,key=key)\n",
    "            \n",
    "        self.norm = eqx.nn.GroupNorm(2, out_channels)\n",
    "        self.act = jax.nn.silu\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        y = self.conv(x)\n",
    "        if self.act_norm:\n",
    "            y = self.act(self.norm(y))\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff54074",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvSC(eqx.Module):\n",
    "    conv: eqx.nn.Conv\n",
    "    def __init__(\n",
    "        self,\n",
    "        key: jax.random.PRNGKey,\n",
    "        C_in: int,\n",
    "        C_out: int,\n",
    "        kernel_size: int=3,\n",
    "        downsampling=False,\n",
    "        upsampling=False,\n",
    "        act_norm: bool=True\n",
    "    )->None:\n",
    "        super(ConvSC, self).__init__()\n",
    "\n",
    "        stride = 2 if downsampling is True else 1\n",
    "        padding = (kernel_size - stride + 1) // 2\n",
    "\n",
    "        self.conv = BasicConv2d(\n",
    "            key,\n",
    "            C_in, \n",
    "            C_out, \n",
    "            kernel_size=kernel_size, \n",
    "            stride=stride,\n",
    "            upsampling=upsampling,\n",
    "            padding=padding,\n",
    "            act_norm=act_norm\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        y = self.conv(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ac0e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxtyping import Array, Float, Int, PyTree  # https://github.com/google/jaxtyping\n",
    "def sampling_generator(N:int, reverse:bool=False)->list:\n",
    "    samplings = [False, True] * (N // 2)\n",
    "    if reverse: \n",
    "        return list(reversed(samplings[:N]))\n",
    "    else: \n",
    "        return samplings[:N]\n",
    "\n",
    "class Encoder(eqx.Module):\n",
    "    \"\"\"3D Encoder for SimVP\"\"\"\n",
    "    enc: list\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        key: jax.random.PRNGKey,\n",
    "        C_in: int,\n",
    "        C_hid: int, \n",
    "        N_S: int, \n",
    "        spatio_kernel: int,\n",
    "    )->None:\n",
    "        super(Encoder, self).__init__()\n",
    "        samplings = sampling_generator(N_S)\n",
    "        keys = jax.random.split(key, N_S)\n",
    "        self.enc = eqx.nn.Sequential([\n",
    "              ConvSC(keys[0], C_in, C_hid, spatio_kernel, downsampling=samplings[0],),\n",
    "            *[ConvSC(k,C_hid, C_hid, spatio_kernel, downsampling=s) for k,s in zip(keys[1:],samplings[1:])]\n",
    "        ]\n",
    "        )\n",
    "        \n",
    "    def __call__(self, x: Array)->Array:\n",
    "        enc1 = self.enc[0](x)\n",
    "        latent = enc1\n",
    "        for i in range(1, len(self.enc)):\n",
    "            latent = self.enc[i](latent)\n",
    "        return latent, enc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d5eff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jrandom.PRNGKey(SEED) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8258444",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8c951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "T, C, H, W = tuple(in_shape)\n",
    "enc = Encoder(key, C, hid_S, N_S, spatio_kernel_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7435556",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, T, C, H, W = x_batch.shape\n",
    "x = x_batch.reshape(B*T, C, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf39713",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed, skip = vmap(enc)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a455a720",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, embed.shape, skip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a2a7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(eqx.Module):\n",
    "    \"\"\"3D Decoder for SimVP\"\"\"\n",
    "    readout: eqx.nn.Conv2d\n",
    "    dec: list\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        key: jax.random.PRNGKey,\n",
    "        C_hid: int,\n",
    "        C_out: int, \n",
    "        N_S: int,\n",
    "        spatio_kernel: int,\n",
    "    )->None:\n",
    "        super(Decoder, self).__init__()\n",
    "        samplings = sampling_generator(N_S, reverse=True)\n",
    "        keys = jax.random.split(key, N_S+1)\n",
    "        self.dec = eqx.nn.Sequential([\n",
    "            *[ConvSC(k, C_hid, C_hid, spatio_kernel, upsampling=s,) for k,s in zip(keys[:-2],samplings[:-1])],\n",
    "              ConvSC(keys[-2],C_hid, C_hid, spatio_kernel, upsampling=samplings[-1])\n",
    "        ])\n",
    "\n",
    "        self.readout = eqx.nn.Conv2d(C_hid, C_out, 1, key=keys[-1],)\n",
    "\n",
    "    def __call__(self, hid, enc1=None):\n",
    "        for i in range(0, len(self.dec)-1):\n",
    "            hid = self.dec[i](hid)\n",
    "        Y = self.dec[-1](hid+enc1)\n",
    "        return self.readout(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "22b1a9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = Decoder(key, hid_S, C, N_S, spatio_kernel_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "042c2061",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = vmap(dec)(embed,skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "46dffe94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160, 1, 64, 64), (160, 1, 64, 64))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "aae11fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimVP(eqx.Module):\n",
    "    enc: Encoder\n",
    "    dec: Decoder\n",
    "    def __init__(\n",
    "        self,\n",
    "        key: jax.random.PRNGKey,\n",
    "        in_shape: Tuple,\n",
    "        hid_S: int=16,\n",
    "        hid_T: int=256,\n",
    "        N_S: int=4,\n",
    "        N_T: int=4,\n",
    "        model_type: str='gSTA',\n",
    "        spatio_kernel_enc: int=3,\n",
    "        spatio_kernel_dec: int=3,\n",
    "    )->None:\n",
    "        super(SimVP, self).__init__()\n",
    "        T, C, H, W = in_shape\n",
    "        keys = jax.random.split(key, 2)\n",
    "        self.enc = Encoder(keys[0], C, hid_S, N_S, spatio_kernel_enc)\n",
    "        self.dec = Decoder(keys[1], hid_S, C, N_S, spatio_kernel_dec)\n",
    "\n",
    "\n",
    "    def __call__(self, x_raw: Array)->Array:\n",
    "        B, T, C, H, W = x_raw.shape\n",
    "        x = x_raw.reshape(B*T, C, H, W)\n",
    "        embed, skip = vmap(self.enc)(x)\n",
    "        return vmap(self.dec)(embed, skip).reshape(B, T, C, H, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacd33f4",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4fac3d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "batch_size = 16\n",
    "val_batch_size=16\n",
    "num_workers=8\n",
    "\n",
    "# model parameters\n",
    "in_shape=[10, 1, 64, 64]  \n",
    "hid_S=64\n",
    "hid_T=256\n",
    "num_layers=6\n",
    "N_T=8\n",
    "groups=4\n",
    "\n",
    "# Training parameters\n",
    "epochs=1000\n",
    "log_step=1\n",
    "lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d791a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 3e-4\n",
    "TOTAL_STEPS = 1500\n",
    "PRINT_EVERY = 30\n",
    "SEED = 42\n",
    "\n",
    "key = jax.random.PRNGKey(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05304e02",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c053ffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimVP(key, tuple(in_shape), hid_S, hid_T, num_layers, N_T, spatio_kernel_enc=spatio_kernel_enc, spatio_kernel_dec=spatio_kernel_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "78baba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(model, x, y):\n",
    "    pred_y = model(x)\n",
    "    # Trains with respect to huber loss\n",
    "    #return optax.losses.huber_loss(pred_y, y).sum()\n",
    "    return optax.losses.l2_loss(pred_y, y).sum()\n",
    "\n",
    "loss = eqx.filter_jit(compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ab34ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: SimVP, testloader: torch.utils.data.DataLoader):\n",
    "    \"\"\"This function evaluates the model on the test dataset,\n",
    "    computing both the average loss and the average accuracy.\n",
    "    \"\"\"\n",
    "    avg_loss = 0\n",
    "    for x, y in testloader:\n",
    "        x = x.numpy()\n",
    "        y = y.numpy()\n",
    "        # Note that all the JAX operations happen inside `loss` ,\n",
    "        # and both have JIT wrappers, so this is fast.\n",
    "        avg_loss += loss(model, x, y)\n",
    "    return avg_loss / len(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "293e7e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_decay_scheduler = optax.cosine_decay_schedule(LEARNING_RATE, decay_steps=TOTAL_STEPS, alpha=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6db7d2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = optax.adamw(learning_rate=cosine_decay_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a0176350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: SimVP,\n",
    "    trainloader: torch.utils.data.DataLoader,\n",
    "    testloader: torch.utils.data.DataLoader,\n",
    "    optim: optax.GradientTransformation,\n",
    "    steps: int,\n",
    "    print_every: int,\n",
    ") -> SimVP:\n",
    "    # Just like earlier: It only makes sense to train the arrays in our model,\n",
    "    # so filter out everything else.\n",
    "    opt_state = optim.init(eqx.filter(model, eqx.is_array))\n",
    "\n",
    "    # Always wrap everything -- computing gradients, running the optimiser, updating\n",
    "    # the model -- into a single JIT region. This ensures things run as fast as\n",
    "    # possible.\n",
    "    @eqx.filter_jit\n",
    "    def make_step(\n",
    "        model: SimVP,\n",
    "        opt_state: PyTree,\n",
    "        x: Float[Array, \"batch 10 1 64 64\"],\n",
    "        y: Float[Array, \"batch 10 1 64 64\"],\n",
    "    ):\n",
    "        loss_value, grads = eqx.filter_value_and_grad(loss)(model, x, y)\n",
    "        updates, opt_state = optim.update(grads, opt_state, model)\n",
    "        model = eqx.apply_updates(model, updates)\n",
    "        return model, opt_state, loss_value\n",
    "\n",
    "    # Loop over our training dataset as many times as we need.\n",
    "    def infinite_trainloader():\n",
    "        while True:\n",
    "            yield from trainloader\n",
    "\n",
    "    for step, (x, y) in zip(range(steps), infinite_trainloader()):\n",
    "        # PyTorch dataloaders give PyTorch tensors by default,\n",
    "        # so convert them to NumPy arrays.\n",
    "        x = x.numpy()\n",
    "        y = y.numpy()\n",
    "        model, opt_state, train_loss = make_step(model, opt_state, x, y)\n",
    "        if (step % print_every) == 0 or (step == steps - 1):\n",
    "            test_loss = evaluate(model, testloader)\n",
    "            print(\n",
    "                f\"{step}, train_loss={train_loss.item()}, test_loss={test_loss.item()}\"\n",
    "            )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c18d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, train_loss=66819.3203125, test_loss=78841.9609375\n",
      "30, train_loss=12492.623046875, test_loss=12646.6259765625\n",
      "60, train_loss=12329.431640625, test_loss=12379.294921875\n",
      "90, train_loss=11546.8603515625, test_loss=12329.7177734375\n",
      "120, train_loss=13075.142578125, test_loss=12279.2744140625\n",
      "150, train_loss=11741.0400390625, test_loss=12291.4951171875\n",
      "180, train_loss=12274.7685546875, test_loss=12248.453125\n",
      "210, train_loss=12309.384765625, test_loss=12240.2294921875\n",
      "240, train_loss=12319.455078125, test_loss=12233.90234375\n",
      "270, train_loss=12109.650390625, test_loss=12215.8271484375\n",
      "300, train_loss=11715.0361328125, test_loss=12208.9091796875\n",
      "330, train_loss=12492.328125, test_loss=12219.3857421875\n",
      "360, train_loss=11388.431640625, test_loss=12201.052734375\n",
      "390, train_loss=12307.001953125, test_loss=12209.7314453125\n",
      "420, train_loss=10747.2216796875, test_loss=12249.8671875\n",
      "450, train_loss=11461.69140625, test_loss=12235.90234375\n",
      "480, train_loss=11432.734375, test_loss=12177.7744140625\n",
      "510, train_loss=11120.3115234375, test_loss=12263.68359375\n",
      "540, train_loss=12133.2724609375, test_loss=12184.6396484375\n",
      "570, train_loss=12655.853515625, test_loss=12197.830078125\n",
      "600, train_loss=12635.951171875, test_loss=12200.51953125\n",
      "630, train_loss=12933.55859375, test_loss=12185.0771484375\n",
      "660, train_loss=11743.662109375, test_loss=12172.8955078125\n",
      "690, train_loss=11583.666015625, test_loss=12172.9130859375\n"
     ]
    }
   ],
   "source": [
    "model = train(model, train_loader, test_loader, optim, TOTAL_STEPS, PRINT_EVERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c2c12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed7973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y_pred[0,0,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b13df7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y_batch[0,0,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffe53ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
